{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c92dc3",
   "metadata": {},
   "source": [
    "Boston dataset is one of the datasets available in sklearn.\n",
    "You are given a Training dataset csv file with X train and Y train data. As studied in lecture, your task is to come up with Gradient Descent algorithm and thus predictions for the test dataset given.\n",
    "\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "\n",
    "1. Code Gradient Descent for N features and come with predictions.\n",
    "\n",
    "2. Try and test with various combinations of learning rates and number of iterations.\n",
    "\n",
    "3. Try using Feature Scaling, and see if it helps you in getting better results. \n",
    "\n",
    "\n",
    "Read Instructions carefully -\n",
    "\n",
    "\n",
    "1. Use Gradient Descent as a training algorithm and submit results predicted.\n",
    "\n",
    "2. Files are in csv format, you can use genfromtxt function in numpy to load data from csv file. Similarly you can use savetxt function to save data into a file.\n",
    "\n",
    "3. Submit a csv file with only predictions for X test data. File name should not have spaces. File should not have any headers and should only have one column i.e. predictions. Also predictions shouldn't be in exponential form.\n",
    "\n",
    "4. Your score is based on coefficient of determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4655b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9783a12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40784991, -0.48772236, -1.2660231 , ...,  0.41057102,\n",
       "        -1.09799011, 37.9       ],\n",
       "       [-0.40737368, -0.48772236,  0.24705682, ...,  0.29116915,\n",
       "        -0.52047412, 21.4       ],\n",
       "       [ 0.1251786 , -0.48772236,  1.01599907, ..., -3.79579542,\n",
       "         0.89107588, 12.7       ],\n",
       "       ...,\n",
       "       [-0.40831101, -0.48772236,  0.24705682, ...,  0.33206621,\n",
       "        -0.33404299, 20.8       ],\n",
       "       [-0.41061997, -0.48772236, -1.15221381, ...,  0.203235  ,\n",
       "        -0.74475218, 22.6       ],\n",
       "       [ 0.34290895, -0.48772236,  1.01599907, ...,  0.38787479,\n",
       "        -1.35871335, 50.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the training dataset\n",
    "import numpy as np\n",
    "training_data = np.loadtxt(\"training_boston.csv\", delimiter = \",\")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91992548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input features (training)\n",
    "X_train = training_data[:,:13]\n",
    "\n",
    "# Output (training)\n",
    "Y_train = training_data[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a112ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of input features (training)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d2161df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of output (training)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab643b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.019628</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.028955</td>\n",
       "      <td>0.028775</td>\n",
       "      <td>0.032202</td>\n",
       "      <td>0.038395</td>\n",
       "      <td>-0.001288</td>\n",
       "      <td>0.043307</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>-0.015785</td>\n",
       "      <td>0.018418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.067490</td>\n",
       "      <td>1.000813</td>\n",
       "      <td>1.017497</td>\n",
       "      <td>1.048995</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>1.001174</td>\n",
       "      <td>0.985209</td>\n",
       "      <td>1.027803</td>\n",
       "      <td>1.016265</td>\n",
       "      <td>1.019974</td>\n",
       "      <td>1.000296</td>\n",
       "      <td>1.015797</td>\n",
       "      <td>1.015377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.516987</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-1.465882</td>\n",
       "      <td>-3.880249</td>\n",
       "      <td>-2.335437</td>\n",
       "      <td>-1.267069</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-1.313990</td>\n",
       "      <td>-2.707379</td>\n",
       "      <td>-3.883072</td>\n",
       "      <td>-1.531127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.408171</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.867691</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.878475</td>\n",
       "      <td>-0.571480</td>\n",
       "      <td>-0.768994</td>\n",
       "      <td>-0.829872</td>\n",
       "      <td>-0.637962</td>\n",
       "      <td>-0.755697</td>\n",
       "      <td>-0.488039</td>\n",
       "      <td>0.197588</td>\n",
       "      <td>-0.828856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.383729</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.180458</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.103479</td>\n",
       "      <td>0.338718</td>\n",
       "      <td>-0.329213</td>\n",
       "      <td>-0.523001</td>\n",
       "      <td>-0.440915</td>\n",
       "      <td>0.297977</td>\n",
       "      <td>0.374827</td>\n",
       "      <td>-0.161629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.055208</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>1.015999</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.628913</td>\n",
       "      <td>0.529069</td>\n",
       "      <td>0.911243</td>\n",
       "      <td>0.674172</td>\n",
       "      <td>1.661245</td>\n",
       "      <td>1.530926</td>\n",
       "      <td>0.806576</td>\n",
       "      <td>0.429868</td>\n",
       "      <td>0.647173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.941735</td>\n",
       "      <td>3.804234</td>\n",
       "      <td>2.422565</td>\n",
       "      <td>3.668398</td>\n",
       "      <td>2.732346</td>\n",
       "      <td>3.555044</td>\n",
       "      <td>1.117494</td>\n",
       "      <td>3.960518</td>\n",
       "      <td>1.661245</td>\n",
       "      <td>1.798194</td>\n",
       "      <td>1.638828</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>3.409999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  379.000000  379.000000  379.000000  379.000000  379.000000  379.000000   \n",
       "mean     0.019628    0.002455    0.036170    0.028955    0.028775    0.032202   \n",
       "std      1.067490    1.000813    1.017497    1.048995    0.999656    1.001174   \n",
       "min     -0.417713   -0.487722   -1.516987   -0.272599   -1.465882   -3.880249   \n",
       "25%     -0.408171   -0.487722   -0.867691   -0.272599   -0.878475   -0.571480   \n",
       "50%     -0.383729   -0.487722   -0.180458   -0.272599   -0.144217   -0.103479   \n",
       "75%      0.055208    0.156071    1.015999   -0.272599    0.628913    0.529069   \n",
       "max      9.941735    3.804234    2.422565    3.668398    2.732346    3.555044   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  379.000000  379.000000  379.000000  379.000000  379.000000  379.000000   \n",
       "mean     0.038395   -0.001288    0.043307    0.043786    0.019218   -0.015785   \n",
       "std      0.985209    1.027803    1.016265    1.019974    1.000296    1.015797   \n",
       "min     -2.335437   -1.267069   -0.982843   -1.313990   -2.707379   -3.883072   \n",
       "25%     -0.768994   -0.829872   -0.637962   -0.755697   -0.488039    0.197588   \n",
       "50%      0.338718   -0.329213   -0.523001   -0.440915    0.297977    0.374827   \n",
       "75%      0.911243    0.674172    1.661245    1.530926    0.806576    0.429868   \n",
       "max      1.117494    3.960518    1.661245    1.798194    1.638828    0.441052   \n",
       "\n",
       "               12  \n",
       "count  379.000000  \n",
       "mean     0.018418  \n",
       "std      1.015377  \n",
       "min     -1.531127  \n",
       "25%     -0.828856  \n",
       "50%     -0.161629  \n",
       "75%      0.647173  \n",
       "max      3.409999  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the input features (training) into Pandas dataframe to check for string, NaN values\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(X_train)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca765f0",
   "metadata": {},
   "source": [
    "You have learnt how to code Gradient Descent for a single featured dataset. Try to code a more Generic Gradient Descent. Let us consider that the $i^{th}$ feature for the first row is $x_1^i$. Similarily for the $j^th$ row, the $i^{th}$ feature will be $x_j^i$.So, your cost function would look something like :\n",
    "\n",
    "$$ cost = \\frac{1}{M}\\sum_i^M (y_i - (m_ix_i^1 + m_ix_i^2 + m_ix_i^3 + ...... + m_{n + 1}x_{n + 1} ))^2 $$\n",
    "\n",
    "Here $m_{n + 1}x_{n + 1}$ is actually 'c', constant value. (We usually take them to be 1)\n",
    "\n",
    "Also, to find the next m (m'), our equation becomes :\n",
    "$$ m_j' = m_j - \\alpha\\frac{\\partial cost}{\\partial m_j} $$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\frac{\\partial cost}{\\partial m_i} = \\frac{1}{M}\\sum_i^M 2(y_i - (m_ix_i^1 + m_ix_i^2 + m_ix_i^3 + ...... + m_{n + 1}x_{n + 1} ))x_i^j $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed9bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds the new gradient at each step\n",
    "def step_gradient(x_, y_, m, learning_rate):\n",
    "    m_slope = np.zeros(len(x_[0]))\n",
    "    M = len(x_)\n",
    "    for i in range(M) :\n",
    "        x = x_[i]\n",
    "        y = y_[i]\n",
    "        for j in range(len(x)):\n",
    "            m_slope[j] += (-2/M) * (y - sum(m * x))*x[j]\n",
    "    new_m = m - learning_rate * m_slope\n",
    "    return new_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b2d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Function\n",
    "def gd(x_, y_, learning_rate, num_iterations):\n",
    "    m = np.zeros(len(x_[0]))     # Intial random values taken as 0\n",
    "    for i in range(num_iterations):\n",
    "        m = step_gradient(x_, y_, m, learning_rate)\n",
    "        print(i, \" Cost: \", cost(x_, y_, m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0dd5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds the new cost after each optimisation\n",
    "def cost(x_, y_, m):\n",
    "    total_cost = 0\n",
    "    M = len(x_)\n",
    "    for i in range(M):\n",
    "        total_cost += (1/M)*((y_[i] - sum(m*x_[i]))**2)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a71c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(x_, y_):\n",
    "    learning_rate = 0.1\n",
    "    num_iterations = 500\n",
    "    m = gd(x_, y_, learning_rate, num_iterations)\n",
    "    print(\"Final m :\", m[0:-1])\n",
    "    print(\"Final c :\", m[-1])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b06c84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (training data)\n",
    "from sklearn import preprocessing\n",
    "standard_scaler_object = preprocessing.StandardScaler()\n",
    "standard_scaler_object.fit(X_train)\n",
    "X_train = standard_scaler_object.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9702066a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Cost:  372.6402282491625\n",
      "1  Cost:  246.08068449886875\n",
      "2  Cost:  166.3146252952613\n",
      "3  Cost:  115.5014638404627\n",
      "4  Cost:  83.05871412434605\n",
      "5  Cost:  62.30835093474387\n",
      "6  Cost:  49.01041492738445\n",
      "7  Cost:  40.46819132006822\n",
      "8  Cost:  34.964357574517365\n",
      "9  Cost:  31.40411193003394\n",
      "10  Cost:  29.08883961950816\n",
      "11  Cost:  27.572339144821747\n",
      "12  Cost:  26.569371917610482\n",
      "13  Cost:  25.897428428927448\n",
      "14  Cost:  25.439610994540992\n",
      "15  Cost:  25.120956642829366\n",
      "16  Cost:  24.893322775748786\n",
      "17  Cost:  24.72573279388676\n",
      "18  Cost:  24.59820571807398\n",
      "19  Cost:  24.497810335880732\n",
      "20  Cost:  24.416140489513502\n",
      "21  Cost:  24.34769871842124\n",
      "22  Cost:  24.288860770386073\n",
      "23  Cost:  24.237211732207697\n",
      "24  Cost:  24.191120020119126\n",
      "25  Cost:  24.149463690506032\n",
      "26  Cost:  24.111454347094874\n",
      "27  Cost:  24.07652362150328\n",
      "28  Cost:  24.044249803514337\n",
      "29  Cost:  24.014310258104167\n",
      "30  Cost:  23.986450424888826\n",
      "31  Cost:  23.960463498173404\n",
      "32  Cost:  23.93617700077588\n",
      "33  Cost:  23.91344381979905\n",
      "34  Cost:  23.892136141002034\n",
      "35  Cost:  23.872141275354984\n",
      "36  Cost:  23.853358728725958\n",
      "37  Cost:  23.83569809513466\n",
      "38  Cost:  23.81907750151465\n",
      "39  Cost:  23.80342242685789\n",
      "40  Cost:  23.788664779806144\n",
      "41  Cost:  23.77474215827951\n",
      "42  Cost:  23.761597240330016\n",
      "43  Cost:  23.749177272046946\n",
      "44  Cost:  23.737433629202133\n",
      "45  Cost:  23.726321436459465\n",
      "46  Cost:  23.715799232694746\n",
      "47  Cost:  23.705828674127247\n",
      "48  Cost:  23.696374269100204\n",
      "49  Cost:  23.687403139812087\n",
      "50  Cost:  23.678884807325915\n",
      "51  Cost:  23.67079099691379\n",
      "52  Cost:  23.66309546132732\n",
      "53  Cost:  23.655773819982592\n",
      "54  Cost:  23.648803412355104\n",
      "55  Cost:  23.642163164117623\n",
      "56  Cost:  23.635833464748124\n",
      "57  Cost:  23.629796055491273\n",
      "58  Cost:  23.624033926689027\n",
      "59  Cost:  23.61853122360585\n",
      "60  Cost:  23.613273159970525\n",
      "61  Cost:  23.608245938536925\n",
      "62  Cost:  23.60343667803953\n",
      "63  Cost:  23.59883334598062\n",
      "64  Cost:  23.594424696742504\n",
      "65  Cost:  23.590200214567496\n",
      "66  Cost:  23.586150060989958\n",
      "67  Cost:  23.58226502634671\n",
      "68  Cost:  23.57853648502371\n",
      "69  Cost:  23.574956354130503\n",
      "70  Cost:  23.571517055320488\n",
      "71  Cost:  23.568211479500476\n",
      "72  Cost:  23.56503295419624\n",
      "73  Cost:  23.561975213360306\n",
      "74  Cost:  23.559032369427385\n",
      "75  Cost:  23.556198887439592\n",
      "76  Cost:  23.553469561077847\n",
      "77  Cost:  23.550839490450905\n",
      "78  Cost:  23.548304061504965\n",
      "79  Cost:  23.545858926928386\n",
      "80  Cost:  23.543499988436857\n",
      "81  Cost:  23.541223380332656\n",
      "82  Cost:  23.53902545424192\n",
      "83  Cost:  23.53690276493944\n",
      "84  Cost:  23.534852057180238\n",
      "85  Cost:  23.532870253461276\n",
      "86  Cost:  23.530954442644017\n",
      "87  Cost:  23.529101869374536\n",
      "88  Cost:  23.527309924240583\n",
      "89  Cost:  23.525576134612734\n",
      "90  Cost:  23.523898156118122\n",
      "91  Cost:  23.522273764701072\n",
      "92  Cost:  23.520700849227772\n",
      "93  Cost:  23.519177404595233\n",
      "94  Cost:  23.51770152530781\n",
      "95  Cost:  23.51627139948836\n",
      "96  Cost:  23.514885303291795\n",
      "97  Cost:  23.513541595692896\n",
      "98  Cost:  23.512238713621365\n",
      "99  Cost:  23.51097516741953\n",
      "100  Cost:  23.509749536599585\n",
      "101  Cost:  23.508560465879814\n",
      "102  Cost:  23.507406661479234\n",
      "103  Cost:  23.50628688765347\n",
      "104  Cost:  23.505199963454206\n",
      "105  Cost:  23.504144759697382\n",
      "106  Cost:  23.503120196124843\n",
      "107  Cost:  23.502125238746824\n",
      "108  Cost:  23.501158897352155\n",
      "109  Cost:  23.50022022317515\n",
      "110  Cost:  23.4993083067083\n",
      "111  Cost:  23.49842227565051\n",
      "112  Cost:  23.49756129298235\n",
      "113  Cost:  23.496724555159002\n",
      "114  Cost:  23.495911290413353\n",
      "115  Cost:  23.49512075716201\n",
      "116  Cost:  23.494352242506764\n",
      "117  Cost:  23.49360506082581\n",
      "118  Cost:  23.492878552448158\n",
      "119  Cost:  23.49217208240626\n",
      "120  Cost:  23.49148503926138\n",
      "121  Cost:  23.49081683399711\n",
      "122  Cost:  23.490166898976245\n",
      "123  Cost:  23.489534686957565\n",
      "124  Cost:  23.48891967016803\n",
      "125  Cost:  23.488321339426967\n",
      "126  Cost:  23.48773920331921\n",
      "127  Cost:  23.487172787413737\n",
      "128  Cost:  23.48662163352509\n",
      "129  Cost:  23.486085299014842\n",
      "130  Cost:  23.48556335613046\n",
      "131  Cost:  23.485055391379696\n",
      "132  Cost:  23.484561004937603\n",
      "133  Cost:  23.484079810084705\n",
      "134  Cost:  23.483611432674337\n",
      "135  Cost:  23.483155510626997\n",
      "136  Cost:  23.482711693450682\n",
      "137  Cost:  23.482279641785098\n",
      "138  Cost:  23.481859026968554\n",
      "139  Cost:  23.48144953062626\n",
      "140  Cost:  23.48105084427868\n",
      "141  Cost:  23.480662668968552\n",
      "142  Cost:  23.480284714906023\n",
      "143  Cost:  23.479916701130264\n",
      "144  Cost:  23.479558355187027\n",
      "145  Cost:  23.47920941282101\n",
      "146  Cost:  23.478869617682346\n",
      "147  Cost:  23.478538721046316\n",
      "148  Cost:  23.47821648154553\n",
      "149  Cost:  23.477902664914065\n",
      "150  Cost:  23.477597043742715\n",
      "151  Cost:  23.47729939724487\n",
      "152  Cost:  23.477009511032325\n",
      "153  Cost:  23.476727176900543\n",
      "154  Cost:  23.4764521926232\n",
      "155  Cost:  23.476184361754843\n",
      "156  Cost:  23.475923493441716\n",
      "157  Cost:  23.475669402240474\n",
      "158  Cost:  23.475421907943918\n",
      "159  Cost:  23.47518083541362\n",
      "160  Cost:  23.474946014419345\n",
      "161  Cost:  23.474717279484434\n",
      "162  Cost:  23.474494469737188\n",
      "163  Cost:  23.474277428767998\n",
      "164  Cost:  23.474066004491768\n",
      "165  Cost:  23.473860049015332\n",
      "166  Cost:  23.47365941850997\n",
      "167  Cost:  23.473463973088553\n",
      "168  Cost:  23.47327357668676\n",
      "169  Cost:  23.473088096949088\n",
      "170  Cost:  23.472907405118335\n",
      "171  Cost:  23.472731375929513\n",
      "172  Cost:  23.472559887506947\n",
      "173  Cost:  23.47239282126532\n",
      "174  Cost:  23.472230061813615\n",
      "175  Cost:  23.472071496862938\n",
      "176  Cost:  23.471917017136796\n",
      "177  Cost:  23.471766516284756\n",
      "178  Cost:  23.471619890798852\n",
      "179  Cost:  23.4714770399326\n",
      "180  Cost:  23.471337865622875\n",
      "181  Cost:  23.471202272414015\n",
      "182  Cost:  23.471070167384553\n",
      "183  Cost:  23.470941460076332\n",
      "184  Cost:  23.470816062425506\n",
      "185  Cost:  23.47069388869612\n",
      "186  Cost:  23.470574855415368\n",
      "187  Cost:  23.47045888131121\n",
      "188  Cost:  23.470345887251565\n",
      "189  Cost:  23.47023579618561\n",
      "190  Cost:  23.47012853308669\n",
      "191  Cost:  23.470024024897064\n",
      "192  Cost:  23.469922200474073\n",
      "193  Cost:  23.469822990538333\n",
      "194  Cost:  23.46972632762304\n",
      "195  Cost:  23.469632146024868\n",
      "196  Cost:  23.469540381756467\n",
      "197  Cost:  23.469450972500304\n",
      "198  Cost:  23.469363857563597\n",
      "199  Cost:  23.469278977834826\n",
      "200  Cost:  23.469196275741425\n",
      "201  Cost:  23.46911569520851\n",
      "202  Cost:  23.469037181619083\n",
      "203  Cost:  23.46896068177509\n",
      "204  Cost:  23.468886143859773\n",
      "205  Cost:  23.46881351740087\n",
      "206  Cost:  23.468742753235183\n",
      "207  Cost:  23.468673803473642\n",
      "208  Cost:  23.468606621467885\n",
      "209  Cost:  23.468541161777345\n",
      "210  Cost:  23.46847738013749\n",
      "211  Cost:  23.468415233428868\n",
      "212  Cost:  23.468354679646833\n",
      "213  Cost:  23.468295677872398\n",
      "214  Cost:  23.468238188243767\n",
      "215  Cost:  23.468182171928543\n",
      "216  Cost:  23.468127591096753\n",
      "217  Cost:  23.468074408894736\n",
      "218  Cost:  23.46802258941944\n",
      "219  Cost:  23.4679720976937\n",
      "220  Cost:  23.46792289964222\n",
      "221  Cost:  23.467874962067686\n",
      "222  Cost:  23.46782825262835\n",
      "223  Cost:  23.467782739815288\n",
      "224  Cost:  23.467738392931086\n",
      "225  Cost:  23.46769518206865\n",
      "226  Cost:  23.46765307809051\n",
      "227  Cost:  23.467612052609102\n",
      "228  Cost:  23.46757207796709\n",
      "229  Cost:  23.46753312721854\n",
      "230  Cost:  23.4674951741104\n",
      "231  Cost:  23.46745819306468\n",
      "232  Cost:  23.467422159160826\n",
      "233  Cost:  23.467387048118823\n",
      "234  Cost:  23.467352836282483\n",
      "235  Cost:  23.46731950060347\n",
      "236  Cost:  23.4672870186256\n",
      "237  Cost:  23.467255368469267\n",
      "238  Cost:  23.46722452881686\n",
      "239  Cost:  23.467194478898218\n",
      "240  Cost:  23.467165198476263\n",
      "241  Cost:  23.467136667833632\n",
      "242  Cost:  23.467108867758743\n",
      "243  Cost:  23.467081779533366\n",
      "244  Cost:  23.46705538491951\n",
      "245  Cost:  23.46702966614709\n",
      "246  Cost:  23.467004605901934\n",
      "247  Cost:  23.46698018731412\n",
      "248  Cost:  23.466956393946457\n",
      "249  Cost:  23.466933209783242\n",
      "250  Cost:  23.466910619219615\n",
      "251  Cost:  23.46688860705088\n",
      "252  Cost:  23.46686715846222\n",
      "253  Cost:  23.466846259018684\n",
      "254  Cost:  23.466825894655393\n",
      "255  Cost:  23.466806051668087\n",
      "256  Cost:  23.466786716703787\n",
      "257  Cost:  23.466767876751817\n",
      "258  Cost:  23.466749519134986\n",
      "259  Cost:  23.46673163150104\n",
      "260  Cost:  23.466714201814288\n",
      "261  Cost:  23.466697218347434\n",
      "262  Cost:  23.46668066967382\n",
      "263  Cost:  23.46666454465957\n",
      "264  Cost:  23.466648832456016\n",
      "265  Cost:  23.466633522492597\n",
      "266  Cost:  23.466618604469424\n",
      "267  Cost:  23.466604068350673\n",
      "268  Cost:  23.46658990435752\n",
      "269  Cost:  23.466576102961717\n",
      "270  Cost:  23.466562654879095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271  Cost:  23.466549551063284\n",
      "272  Cost:  23.466536782699702\n",
      "273  Cost:  23.46652434119951\n",
      "274  Cost:  23.46651221819387\n",
      "275  Cost:  23.46650040552835\n",
      "276  Cost:  23.466488895257342\n",
      "277  Cost:  23.466477679638718\n",
      "278  Cost:  23.466466751128735\n",
      "279  Cost:  23.466456102376725\n",
      "280  Cost:  23.466445726220318\n",
      "281  Cost:  23.466435615680663\n",
      "282  Cost:  23.466425763957496\n",
      "283  Cost:  23.466416164424825\n",
      "284  Cost:  23.466406810626186\n",
      "285  Cost:  23.466397696270644\n",
      "286  Cost:  23.466388815228218\n",
      "287  Cost:  23.4663801615259\n",
      "288  Cost:  23.466371729343738\n",
      "289  Cost:  23.466363513010684\n",
      "290  Cost:  23.466355507000934\n",
      "291  Cost:  23.466347705930268\n",
      "292  Cost:  23.466340104552202\n",
      "293  Cost:  23.46633269775463\n",
      "294  Cost:  23.466325480556364\n",
      "295  Cost:  23.466318448103763\n",
      "296  Cost:  23.466311595667413\n",
      "297  Cost:  23.46630491863897\n",
      "298  Cost:  23.466298412528168\n",
      "299  Cost:  23.466292072959657\n",
      "300  Cost:  23.46628589567006\n",
      "301  Cost:  23.46627987650522\n",
      "302  Cost:  23.466274011417322\n",
      "303  Cost:  23.46626829646216\n",
      "304  Cost:  23.46626272779654\n",
      "305  Cost:  23.466257301675643\n",
      "306  Cost:  23.466252014450472\n",
      "307  Cost:  23.466246862565526\n",
      "308  Cost:  23.46624184255633\n",
      "309  Cost:  23.466236951047026\n",
      "310  Cost:  23.466232184748257\n",
      "311  Cost:  23.466227540454856\n",
      "312  Cost:  23.46622301504362\n",
      "313  Cost:  23.466218605471465\n",
      "314  Cost:  23.466214308773065\n",
      "315  Cost:  23.466210122059145\n",
      "316  Cost:  23.466206042514234\n",
      "317  Cost:  23.46620206739501\n",
      "318  Cost:  23.46619819402845\n",
      "319  Cost:  23.466194419809884\n",
      "320  Cost:  23.46619074220128\n",
      "321  Cost:  23.466187158729703\n",
      "322  Cost:  23.4661836669854\n",
      "323  Cost:  23.466180264620355\n",
      "324  Cost:  23.466176949346657\n",
      "325  Cost:  23.466173718934996\n",
      "326  Cost:  23.466170571213112\n",
      "327  Cost:  23.46616750406428\n",
      "328  Cost:  23.46616451542603\n",
      "329  Cost:  23.466161603288715\n",
      "330  Cost:  23.46615876569407\n",
      "331  Cost:  23.466156000733992\n",
      "332  Cost:  23.466153306549224\n",
      "333  Cost:  23.466150681328074\n",
      "334  Cost:  23.466148123305235\n",
      "335  Cost:  23.466145630760636\n",
      "336  Cost:  23.466143202018188\n",
      "337  Cost:  23.466140835444698\n",
      "338  Cost:  23.466138529448788\n",
      "339  Cost:  23.466136282479884\n",
      "340  Cost:  23.466134093027012\n",
      "341  Cost:  23.466131959617933\n",
      "342  Cost:  23.466129880818063\n",
      "343  Cost:  23.46612785522951\n",
      "344  Cost:  23.466125881490257\n",
      "345  Cost:  23.466123958273116\n",
      "346  Cost:  23.466122084284798\n",
      "347  Cost:  23.466120258265224\n",
      "348  Cost:  23.466118478986477\n",
      "349  Cost:  23.466116745252176\n",
      "350  Cost:  23.466115055896466\n",
      "351  Cost:  23.466113409783393\n",
      "352  Cost:  23.466111805806072\n",
      "353  Cost:  23.46611024288593\n",
      "354  Cost:  23.466108719972024\n",
      "355  Cost:  23.46610723604029\n",
      "356  Cost:  23.46610579009293\n",
      "357  Cost:  23.466104381157614\n",
      "358  Cost:  23.46610300828695\n",
      "359  Cost:  23.46610167055778\n",
      "360  Cost:  23.46610036707057\n",
      "361  Cost:  23.466099096948856\n",
      "362  Cost:  23.466097859338547\n",
      "363  Cost:  23.466096653407487\n",
      "364  Cost:  23.466095478344673\n",
      "365  Cost:  23.46609433336006\n",
      "366  Cost:  23.466093217683742\n",
      "367  Cost:  23.466092130565453\n",
      "368  Cost:  23.46609107127418\n",
      "369  Cost:  23.46609003909772\n",
      "370  Cost:  23.46608903334192\n",
      "371  Cost:  23.466088053330537\n",
      "372  Cost:  23.466087098404554\n",
      "373  Cost:  23.466086167921873\n",
      "374  Cost:  23.466085261256847\n",
      "375  Cost:  23.46608437779976\n",
      "376  Cost:  23.466083516956562\n",
      "377  Cost:  23.466082678148428\n",
      "378  Cost:  23.46608186081134\n",
      "379  Cost:  23.46608106439565\n",
      "380  Cost:  23.46608028836589\n",
      "381  Cost:  23.46607953220019\n",
      "382  Cost:  23.46607879539009\n",
      "383  Cost:  23.46607807744016\n",
      "384  Cost:  23.466077377867656\n",
      "385  Cost:  23.466076696202137\n",
      "386  Cost:  23.466076031985256\n",
      "387  Cost:  23.466075384770356\n",
      "388  Cost:  23.46607475412226\n",
      "389  Cost:  23.46607413961688\n",
      "390  Cost:  23.466073540841016\n",
      "391  Cost:  23.46607295739207\n",
      "392  Cost:  23.466072388877674\n",
      "393  Cost:  23.466071834915578\n",
      "394  Cost:  23.46607129513328\n",
      "395  Cost:  23.46607076916782\n",
      "396  Cost:  23.46607025666551\n",
      "397  Cost:  23.466069757281765\n",
      "398  Cost:  23.466069270680727\n",
      "399  Cost:  23.466068796535282\n",
      "400  Cost:  23.466068334526497\n",
      "401  Cost:  23.466067884343826\n",
      "402  Cost:  23.466067445684505\n",
      "403  Cost:  23.466067018253533\n",
      "404  Cost:  23.466066601763558\n",
      "405  Cost:  23.466066195934474\n",
      "406  Cost:  23.466065800493432\n",
      "407  Cost:  23.466065415174487\n",
      "408  Cost:  23.466065039718583\n",
      "409  Cost:  23.466064673873245\n",
      "410  Cost:  23.466064317392444\n",
      "411  Cost:  23.466063970036508\n",
      "412  Cost:  23.466063631571874\n",
      "413  Cost:  23.466063301770912\n",
      "414  Cost:  23.466062980411863\n",
      "415  Cost:  23.46606266727868\n",
      "416  Cost:  23.46606236216076\n",
      "417  Cost:  23.46606206485297\n",
      "418  Cost:  23.466061775155378\n",
      "419  Cost:  23.46606149287321\n",
      "420  Cost:  23.466061217816602\n",
      "421  Cost:  23.466060949800617\n",
      "422  Cost:  23.46606068864507\n",
      "423  Cost:  23.466060434174295\n",
      "424  Cost:  23.46606018621727\n",
      "425  Cost:  23.466059944607167\n",
      "426  Cost:  23.466059709181597\n",
      "427  Cost:  23.466059479782214\n",
      "428  Cost:  23.466059256254766\n",
      "429  Cost:  23.46605903844896\n",
      "430  Cost:  23.466058826218337\n",
      "431  Cost:  23.466058619420217\n",
      "432  Cost:  23.4660584179155\n",
      "433  Cost:  23.466058221568687\n",
      "434  Cost:  23.466058030247787\n",
      "435  Cost:  23.46605784382413\n",
      "436  Cost:  23.46605766217237\n",
      "437  Cost:  23.46605748517034\n",
      "438  Cost:  23.466057312699057\n",
      "439  Cost:  23.466057144642548\n",
      "440  Cost:  23.466056980887714\n",
      "441  Cost:  23.466056821324624\n",
      "442  Cost:  23.466056665845777\n",
      "443  Cost:  23.466056514346782\n",
      "444  Cost:  23.466056366725716\n",
      "445  Cost:  23.466056222883292\n",
      "446  Cost:  23.4660560827228\n",
      "447  Cost:  23.46605594615002\n",
      "448  Cost:  23.466055813073076\n",
      "449  Cost:  23.466055683402537\n",
      "450  Cost:  23.46605555705116\n",
      "451  Cost:  23.46605543393402\n",
      "452  Cost:  23.46605531396828\n",
      "453  Cost:  23.466055197073334\n",
      "454  Cost:  23.466055083170534\n",
      "455  Cost:  23.466054972183343\n",
      "456  Cost:  23.466054864037062\n",
      "457  Cost:  23.466054758659013\n",
      "458  Cost:  23.466054655978358\n",
      "459  Cost:  23.466054555925986\n",
      "460  Cost:  23.466054458434673\n",
      "461  Cost:  23.46605436343885\n",
      "462  Cost:  23.46605427087461\n",
      "463  Cost:  23.466054180679766\n",
      "464  Cost:  23.46605409279365\n",
      "465  Cost:  23.466054007157148\n",
      "466  Cost:  23.466053923712686\n",
      "467  Cost:  23.46605384240415\n",
      "468  Cost:  23.466053763176895\n",
      "469  Cost:  23.46605368597759\n",
      "470  Cost:  23.466053610754383\n",
      "471  Cost:  23.466053537456645\n",
      "472  Cost:  23.466053466035124\n",
      "473  Cost:  23.466053396441776\n",
      "474  Cost:  23.46605332862983\n",
      "475  Cost:  23.46605326255367\n",
      "476  Cost:  23.466053198168837\n",
      "477  Cost:  23.466053135432087\n",
      "478  Cost:  23.46605307430118\n",
      "479  Cost:  23.466053014735095\n",
      "480  Cost:  23.466052956693673\n",
      "481  Cost:  23.466052900137974\n",
      "482  Cost:  23.466052845029903\n",
      "483  Cost:  23.466052791332487\n",
      "484  Cost:  23.466052739009495\n",
      "485  Cost:  23.46605268802588\n",
      "486  Cost:  23.466052638347254\n",
      "487  Cost:  23.466052589940247\n",
      "488  Cost:  23.46605254277238\n",
      "489  Cost:  23.46605249681182\n",
      "490  Cost:  23.4660524520277\n",
      "491  Cost:  23.466052408389956\n",
      "492  Cost:  23.4660523658692\n",
      "493  Cost:  23.466052324436838\n",
      "494  Cost:  23.466052284065\n",
      "495  Cost:  23.46605224472662\n",
      "496  Cost:  23.466052206395155\n",
      "497  Cost:  23.466052169044847\n",
      "498  Cost:  23.466052132650624\n",
      "499  Cost:  23.466052097187955\n",
      "Final m : [-0.99989815  0.74021107  0.01055105  0.81820399 -2.17076332  2.35409904\n",
      "  0.12121256 -3.03049815  2.56796065 -1.73131496 -2.24910815  0.59680351\n",
      " -4.32345565]\n",
      "Final c : 22.60949868073878\n"
     ]
    }
   ],
   "source": [
    "x_ = np.append(X_train, np.ones(len(X_train)).reshape(-1, 1), axis = 1)\n",
    "y_ = Y_train\n",
    "m = run(x_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a099427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.91816626, -0.48772236,  1.01599907, ...,  0.80657583,\n",
       "        -1.59755122,  1.04106182],\n",
       "       [-0.40339151, -0.48772236,  0.40609801, ..., -1.13534664,\n",
       "         0.44105193, -0.89473812],\n",
       "       [-0.4131781 , -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.50084979],\n",
       "       ...,\n",
       "       [-0.41001449,  2.08745172, -1.37837329, ..., -0.0719129 ,\n",
       "         0.39094481, -0.68167397],\n",
       "       [-0.40317611, -0.48772236, -0.37597609, ...,  1.13022958,\n",
       "         0.34007019,  0.20142086],\n",
       "       [-0.13356344, -0.48772236,  1.2319449 , ..., -1.73641788,\n",
       "        -2.93893082,  0.48877712]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the testing dataset\n",
    "import numpy as np\n",
    "testing_data = np.loadtxt(\"testing_boston.csv\", delimiter = \",\")\n",
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c611d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input features (testing)\n",
    "X_test = testing_data[:,:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8060267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of input features (training)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97d99ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.058575</td>\n",
       "      <td>-0.007327</td>\n",
       "      <td>-0.107939</td>\n",
       "      <td>-0.086410</td>\n",
       "      <td>-0.085871</td>\n",
       "      <td>-0.096098</td>\n",
       "      <td>-0.114581</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>-0.129240</td>\n",
       "      <td>-0.130670</td>\n",
       "      <td>-0.057350</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>-0.054965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.769837</td>\n",
       "      <td>1.005445</td>\n",
       "      <td>0.945672</td>\n",
       "      <td>0.839435</td>\n",
       "      <td>1.003998</td>\n",
       "      <td>0.998196</td>\n",
       "      <td>1.042254</td>\n",
       "      <td>0.920171</td>\n",
       "      <td>0.946051</td>\n",
       "      <td>0.933732</td>\n",
       "      <td>1.004824</td>\n",
       "      <td>0.957787</td>\n",
       "      <td>0.958559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.417173</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.557842</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-1.431329</td>\n",
       "      <td>-3.058221</td>\n",
       "      <td>-2.225199</td>\n",
       "      <td>-1.263551</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-1.308051</td>\n",
       "      <td>-2.707379</td>\n",
       "      <td>-3.907193</td>\n",
       "      <td>-1.496084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.410832</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.891036</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.947582</td>\n",
       "      <td>-0.567918</td>\n",
       "      <td>-1.240171</td>\n",
       "      <td>-0.762417</td>\n",
       "      <td>-0.637962</td>\n",
       "      <td>-0.785394</td>\n",
       "      <td>-0.765457</td>\n",
       "      <td>0.246544</td>\n",
       "      <td>-0.678870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.398269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.375976</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.299707</td>\n",
       "      <td>-0.127698</td>\n",
       "      <td>0.111130</td>\n",
       "      <td>-0.202052</td>\n",
       "      <td>-0.523001</td>\n",
       "      <td>-0.601276</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.396098</td>\n",
       "      <td>-0.283580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.242900</td>\n",
       "      <td>-0.219475</td>\n",
       "      <td>1.015999</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.434551</td>\n",
       "      <td>0.283316</td>\n",
       "      <td>0.898797</td>\n",
       "      <td>0.604198</td>\n",
       "      <td>-0.350561</td>\n",
       "      <td>0.072833</td>\n",
       "      <td>0.806576</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>0.389254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.966816</td>\n",
       "      <td>3.589637</td>\n",
       "      <td>2.117615</td>\n",
       "      <td>3.668398</td>\n",
       "      <td>2.732346</td>\n",
       "      <td>3.476688</td>\n",
       "      <td>1.117494</td>\n",
       "      <td>3.287300</td>\n",
       "      <td>1.661245</td>\n",
       "      <td>1.530926</td>\n",
       "      <td>1.268938</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>3.548771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  127.000000  127.000000  127.000000  127.000000  127.000000  127.000000   \n",
       "mean    -0.058575   -0.007327   -0.107939   -0.086410   -0.085871   -0.096098   \n",
       "std      0.769837    1.005445    0.945672    0.839435    1.003998    0.998196   \n",
       "min     -0.417173   -0.487722   -1.557842   -0.272599   -1.431329   -3.058221   \n",
       "25%     -0.410832   -0.487722   -0.891036   -0.272599   -0.947582   -0.567918   \n",
       "50%     -0.398269   -0.487722   -0.375976   -0.272599   -0.299707   -0.127698   \n",
       "75%     -0.242900   -0.219475    1.015999   -0.272599    0.434551    0.283316   \n",
       "max      3.966816    3.589637    2.117615    3.668398    2.732346    3.476688   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  127.000000  127.000000  127.000000  127.000000  127.000000  127.000000   \n",
       "mean    -0.114581    0.003845   -0.129240   -0.130670   -0.057350    0.047105   \n",
       "std      1.042254    0.920171    0.946051    0.933732    1.004824    0.957787   \n",
       "min     -2.225199   -1.263551   -0.982843   -1.308051   -2.707379   -3.907193   \n",
       "25%     -1.240171   -0.762417   -0.637962   -0.785394   -0.765457    0.246544   \n",
       "50%      0.111130   -0.202052   -0.523001   -0.601276    0.113032    0.396098   \n",
       "75%      0.898797    0.604198   -0.350561    0.072833    0.806576    0.441052   \n",
       "max      1.117494    3.287300    1.661245    1.530926    1.268938    0.441052   \n",
       "\n",
       "               12  \n",
       "count  127.000000  \n",
       "mean    -0.054965  \n",
       "std      0.958559  \n",
       "min     -1.496084  \n",
       "25%     -0.678870  \n",
       "50%     -0.283580  \n",
       "75%      0.389254  \n",
       "max      3.548771  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the input features (testing) into Pandas dataframe to check for string, NaN values\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(X_test)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e4788c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (testing data)\n",
    "standard_scaler_object = preprocessing.StandardScaler()\n",
    "standard_scaler_object.fit(X_test)\n",
    "X_test = standard_scaler_object.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3794f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = np.append(X_test, np.ones(len(X_test)).reshape(-1, 1), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553da3d",
   "metadata": {},
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d416aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(final_m, testing_data):\n",
    "    y_pred = []\n",
    "    for i in testing_data:\n",
    "        ans = sum(i * m)\n",
    "        y_pred.append(ans)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "029a7efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.11689676206052,\n",
       " 28.729862780718193,\n",
       " 22.527728851834723,\n",
       " 23.98661842522167,\n",
       " 20.51449806223987,\n",
       " 1.9041072424365026,\n",
       " 30.561375942894276,\n",
       " 24.808123365414538,\n",
       " 18.473831208655973,\n",
       " 23.50888057538465,\n",
       " 23.92593205019116,\n",
       " 17.39232932531255,\n",
       " 16.540449973171512,\n",
       " 21.193879991549576,\n",
       " 43.40783765204707,\n",
       " 23.27204074528622,\n",
       " 24.215604876229712,\n",
       " 27.591785664018538,\n",
       " 19.492685511758257,\n",
       " 31.27995275548348,\n",
       " 23.70459756417188,\n",
       " 24.867249909132738,\n",
       " 34.250092424967214,\n",
       " 37.367001417000786,\n",
       " 31.432735312267575,\n",
       " 16.268602668724597,\n",
       " 23.406962643998657,\n",
       " 32.83989230967916,\n",
       " 25.752154574644198,\n",
       " 34.63649623030613,\n",
       " 16.49696154226031,\n",
       " 25.916946187500038,\n",
       " 23.380497536430887,\n",
       " 25.228093601125256,\n",
       " 13.909407389028589,\n",
       " 29.740599896982882,\n",
       " 26.030240035913334,\n",
       " 20.266745742213566,\n",
       " 23.90014282686455,\n",
       " 8.159321773071246,\n",
       " 7.398852207833844,\n",
       " 28.72205593137585,\n",
       " 28.956681760803242,\n",
       " 19.712674123478592,\n",
       " 20.071597057248702,\n",
       " 1.8482488427103156,\n",
       " 39.87826904788368,\n",
       " 25.667525238686302,\n",
       " 29.762249970860843,\n",
       " 16.32615391278278,\n",
       " 17.426375844149334,\n",
       " 41.03015562493056,\n",
       " 17.134291222131672,\n",
       " 20.916410516678802,\n",
       " 15.125615490866618,\n",
       " 21.256350765459054,\n",
       " 18.079660477813306,\n",
       " 23.088379512352276,\n",
       " 13.137458353380595,\n",
       " 16.80165163878729,\n",
       " 13.436444841314323,\n",
       " 29.322785841063386,\n",
       " 25.047675599226785,\n",
       " 25.42527590749907,\n",
       " 16.96280649126199,\n",
       " 16.852130624066827,\n",
       " 34.94932867409452,\n",
       " 16.591973511717015,\n",
       " 27.813468497072325,\n",
       " 22.34819517149614,\n",
       " 29.300767420835964,\n",
       " 27.039129706019143,\n",
       " 17.558118016651157,\n",
       " 4.3984590693687124,\n",
       " 36.65328333385854,\n",
       " 24.880170970373797,\n",
       " 30.150914680928757,\n",
       " 27.221704479300193,\n",
       " 15.464102912993905,\n",
       " 31.915352477191405,\n",
       " 19.218223809908494,\n",
       " 22.64732101352305,\n",
       " 21.76695124474231,\n",
       " 7.342849970909613,\n",
       " 16.901145115671973,\n",
       " 29.03232666913096,\n",
       " 26.68184174820923,\n",
       " 4.852998210170977,\n",
       " 21.97817367346156,\n",
       " 19.900432092517217,\n",
       " 21.82324007807761,\n",
       " 20.43906380752381,\n",
       " 20.608066104769456,\n",
       " 12.807863608415964,\n",
       " 19.50782434512376,\n",
       " 26.18580371058851,\n",
       " 40.190929849938264,\n",
       " 19.71984151303812,\n",
       " 33.67743642463378,\n",
       " 26.687974388137903,\n",
       " 28.943511094785876,\n",
       " 21.48490988341046,\n",
       " 26.48191873870852,\n",
       " 31.53103075717382,\n",
       " 16.695644689323622,\n",
       " 26.368284090374548,\n",
       " 20.894941288442368,\n",
       " 36.4167956504879,\n",
       " 21.53115488602362,\n",
       " 16.076454943423407,\n",
       " 26.907674932733414,\n",
       " -1.4717830398525464,\n",
       " 13.457486757596673,\n",
       " 16.278034243682377,\n",
       " 36.092467332881384,\n",
       " 20.72340132361696,\n",
       " 20.486748556260814,\n",
       " 25.278870312940633,\n",
       " 21.267072743395996,\n",
       " 18.823846027507834,\n",
       " 12.947053806652129,\n",
       " 35.7683113710241,\n",
       " 22.837911972491305,\n",
       " 24.624842418448935,\n",
       " 16.178250857837746,\n",
       " 20.70797643671388,\n",
       " 14.431303884506688]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(m, testing_data)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78f21ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the output obtained from the evaluation data into a \"CSV\" file\n",
    "np.savetxt('Boston Predictions.csv', y_pred, fmt = '%.5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
